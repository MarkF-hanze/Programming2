{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b3a2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext('local[8]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bec20e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"pokemon.csv\"\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "sc.addFile(url)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49669749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.read.csv(SparkFiles.get(\"pokemon.csv\"), header=True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6730da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- abilities: string (nullable = true)\n",
      " |-- against_bug: double (nullable = true)\n",
      " |-- against_dark: double (nullable = true)\n",
      " |-- against_dragon: double (nullable = true)\n",
      " |-- against_electric: double (nullable = true)\n",
      " |-- against_fairy: double (nullable = true)\n",
      " |-- against_fight: double (nullable = true)\n",
      " |-- against_fire: double (nullable = true)\n",
      " |-- against_flying: double (nullable = true)\n",
      " |-- against_ghost: double (nullable = true)\n",
      " |-- against_grass: double (nullable = true)\n",
      " |-- against_ground: double (nullable = true)\n",
      " |-- against_ice: double (nullable = true)\n",
      " |-- against_normal: double (nullable = true)\n",
      " |-- against_poison: double (nullable = true)\n",
      " |-- against_psychic: double (nullable = true)\n",
      " |-- against_rock: double (nullable = true)\n",
      " |-- against_steel: double (nullable = true)\n",
      " |-- against_water: double (nullable = true)\n",
      " |-- attack: integer (nullable = true)\n",
      " |-- base_egg_steps: integer (nullable = true)\n",
      " |-- base_happiness: integer (nullable = true)\n",
      " |-- base_total: integer (nullable = true)\n",
      " |-- capture_rate: string (nullable = true)\n",
      " |-- classfication: string (nullable = true)\n",
      " |-- defense: integer (nullable = true)\n",
      " |-- experience_growth: integer (nullable = true)\n",
      " |-- height_m: double (nullable = true)\n",
      " |-- hp: integer (nullable = true)\n",
      " |-- japanese_name: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- percentage_male: double (nullable = true)\n",
      " |-- pokedex_number: integer (nullable = true)\n",
      " |-- sp_attack: integer (nullable = true)\n",
      " |-- sp_defense: integer (nullable = true)\n",
      " |-- speed: integer (nullable = true)\n",
      " |-- type1: string (nullable = true)\n",
      " |-- type2: string (nullable = true)\n",
      " |-- weight_kg: double (nullable = true)\n",
      " |-- generation: integer (nullable = true)\n",
      " |-- is_legendary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0165a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+------------+--------------+----------------+-------------+-------------+------------+--------------+-------------+-------------+--------------+-----------+--------------+--------------+---------------+------------+-------------+-------------+------+--------------+--------------+----------+------------+--------------+-------+-----------------+--------+---+---------------------+----------+---------------+--------------+---------+----------+-----+-----+------+---------+----------+------------+\n",
      "|           abilities|against_bug|against_dark|against_dragon|against_electric|against_fairy|against_fight|against_fire|against_flying|against_ghost|against_grass|against_ground|against_ice|against_normal|against_poison|against_psychic|against_rock|against_steel|against_water|attack|base_egg_steps|base_happiness|base_total|capture_rate| classfication|defense|experience_growth|height_m| hp|        japanese_name|      name|percentage_male|pokedex_number|sp_attack|sp_defense|speed|type1| type2|weight_kg|generation|is_legendary|\n",
      "+--------------------+-----------+------------+--------------+----------------+-------------+-------------+------------+--------------+-------------+-------------+--------------+-----------+--------------+--------------+---------------+------------+-------------+-------------+------+--------------+--------------+----------+------------+--------------+-------+-----------------+--------+---+---------------------+----------+---------------+--------------+---------+----------+-----+-----+------+---------+----------+------------+\n",
      "|['Overgrow', 'Chl...|        1.0|         1.0|           1.0|             0.5|          0.5|          0.5|         2.0|           2.0|          1.0|         0.25|           1.0|        2.0|           1.0|           1.0|            2.0|         1.0|          1.0|          0.5|    49|          5120|            70|       318|          45|  Seed Pokémon|     49|          1059860|     0.7| 45|Fushigidaneフシギダネ| Bulbasaur|           88.1|             1|       65|        65|   45|grass|poison|      6.9|         1|           0|\n",
      "|['Overgrow', 'Chl...|        1.0|         1.0|           1.0|             0.5|          0.5|          0.5|         2.0|           2.0|          1.0|         0.25|           1.0|        2.0|           1.0|           1.0|            2.0|         1.0|          1.0|          0.5|    62|          5120|            70|       405|          45|  Seed Pokémon|     63|          1059860|     1.0| 60| Fushigisouフシギソウ|   Ivysaur|           88.1|             2|       80|        80|   60|grass|poison|     13.0|         1|           0|\n",
      "|['Overgrow', 'Chl...|        1.0|         1.0|           1.0|             0.5|          0.5|          0.5|         2.0|           2.0|          1.0|         0.25|           1.0|        2.0|           1.0|           1.0|            2.0|         1.0|          1.0|          0.5|   100|          5120|            70|       625|          45|  Seed Pokémon|    123|          1059860|     2.0| 80|Fushigibanaフシギバナ|  Venusaur|           88.1|             3|      122|       120|   80|grass|poison|    100.0|         1|           0|\n",
      "|['Blaze', 'Solar ...|        0.5|         1.0|           1.0|             1.0|          0.5|          1.0|         0.5|           1.0|          1.0|          0.5|           2.0|        0.5|           1.0|           1.0|            1.0|         2.0|          0.5|          2.0|    52|          5120|            70|       309|          45|Lizard Pokémon|     43|          1059860|     0.6| 39|     Hitokageヒトカゲ|Charmander|           88.1|             4|       60|        50|   65| fire|  null|      8.5|         1|           0|\n",
      "|['Blaze', 'Solar ...|        0.5|         1.0|           1.0|             1.0|          0.5|          1.0|         0.5|           1.0|          1.0|          0.5|           2.0|        0.5|           1.0|           1.0|            1.0|         2.0|          0.5|          2.0|    64|          5120|            70|       405|          45| Flame Pokémon|     58|          1059860|     1.1| 58|      Lizardoリザード|Charmeleon|           88.1|             5|       80|        65|   80| fire|  null|     19.0|         1|           0|\n",
      "+--------------------+-----------+------------+--------------+----------------+-------------+-------------+------------+--------------+-------------+-------------+--------------+-----------+--------------+--------------+---------------+------------+-------------+-------------+------+--------------+--------------+----------+------------+--------------+-------+-----------------+--------+---+---------------------+----------+---------------+--------------+---------+----------+-----+-----+------+---------+----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d24c666",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Unsupported class file major version 55'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o325.count.\n: java.lang.IllegalArgumentException: Unsupported class file major version 55\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\r\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\r\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\r\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\r\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\r\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\r\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\r\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\r\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\r\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2100)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeCollect(SparkPlan.scala:299)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2831)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2830)\r\n\tat org.apache.spark.sql.Dataset$$anonfun$53.apply(Dataset.scala:3365)\r\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\r\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\r\n\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2830)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3c9a60fd698f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \"\"\"\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 55'"
     ]
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3276d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+\n",
      "|attack|defense|\n",
      "+------+-------+\n",
      "|    49|     49|\n",
      "|    62|     63|\n",
      "|   100|    123|\n",
      "|    52|     43|\n",
      "|    64|     58|\n",
      "+------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('attack', 'defense').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "80851e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   type1|count|\n",
      "+--------+-----+\n",
      "|   water|  114|\n",
      "|  normal|  105|\n",
      "|   grass|   78|\n",
      "|     bug|   72|\n",
      "| psychic|   53|\n",
      "|    fire|   52|\n",
      "|    rock|   45|\n",
      "|electric|   39|\n",
      "|  ground|   32|\n",
      "|  poison|   32|\n",
      "|    dark|   29|\n",
      "|fighting|   28|\n",
      "|   ghost|   27|\n",
      "|  dragon|   27|\n",
      "|   steel|   24|\n",
      "|     ice|   23|\n",
      "|   fairy|   18|\n",
      "|  flying|    3|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many are there of each type?\n",
    "df.groupBy(\"type1\").count().sort(\"count\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3bd0f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Unsupported class file major version 55'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o325.describe.\n: java.lang.IllegalArgumentException: Unsupported class file major version 55\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136)\r\n\tat org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237)\r\n\tat org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500)\r\n\tat scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134)\r\n\tat scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236)\r\n\tat scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40)\r\n\tat scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134)\r\n\tat scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732)\r\n\tat org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500)\r\n\tat org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175)\r\n\tat org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631)\r\n\tat org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307)\r\n\tat org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306)\r\n\tat scala.collection.immutable.List.foreach(List.scala:392)\r\n\tat org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306)\r\n\tat org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162)\r\n\tat org.apache.spark.SparkContext.clean(SparkContext.scala:2326)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2100)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:363)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:944)\r\n\tat org.apache.spark.sql.execution.stat.StatFunctions$.aggResult$lzycompute$1(StatFunctions.scala:273)\r\n\tat org.apache.spark.sql.execution.stat.StatFunctions$.org$apache$spark$sql$execution$stat$StatFunctions$$aggResult$1(StatFunctions.scala:273)\r\n\tat org.apache.spark.sql.execution.stat.StatFunctions$$anonfun$summary$2.apply$mcVI$sp(StatFunctions.scala:286)\r\n\tat scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:160)\r\n\tat org.apache.spark.sql.execution.stat.StatFunctions$.summary(StatFunctions.scala:285)\r\n\tat org.apache.spark.sql.Dataset.summary(Dataset.scala:2534)\r\n\tat org.apache.spark.sql.Dataset.describe(Dataset.scala:2473)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-934a7bba20fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'attack'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mdescribe\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   1170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m             \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1172\u001b[1;33m         \u001b[0mjdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1173\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pysparkEnv\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: 'Unsupported class file major version 55'"
     ]
    }
   ],
   "source": [
    "df.describe('attack').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20df2989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+---+---+---+---+---+---+\n",
      "|type1_generation|  1|  2|  3|  4|  5|  6|  7|\n",
      "+----------------+---+---+---+---+---+---+---+\n",
      "|             bug| 12| 10| 12|  8| 18|  3|  9|\n",
      "|            dark|  0|  5|  4|  3| 13|  3|  1|\n",
      "|          dragon|  3|  0|  7|  3|  7|  4|  3|\n",
      "|        electric|  9|  6|  4|  7|  7|  3|  3|\n",
      "|           fairy|  2|  5|  0|  1|  0|  9|  1|\n",
      "|        fighting|  7|  2|  4|  2|  7|  3|  3|\n",
      "|            fire| 12|  8|  6|  5|  8|  8|  5|\n",
      "|          flying|  0|  0|  0|  0|  1|  2|  0|\n",
      "|           ghost|  3|  1|  4|  6|  5|  4|  4|\n",
      "|           grass| 12|  9| 12| 13| 15|  5| 12|\n",
      "|          ground|  8|  3|  6|  4|  9|  0|  2|\n",
      "|             ice|  2|  4|  6|  3|  6|  2|  0|\n",
      "|          normal| 22| 15| 18| 17| 17|  4| 12|\n",
      "|          poison| 14|  1|  3|  6|  2|  2|  4|\n",
      "|         psychic|  8|  7|  8|  7| 14|  3|  6|\n",
      "|            rock|  9|  4|  8|  6|  6|  8|  4|\n",
      "|           steel|  0|  2|  9|  3|  4|  4|  2|\n",
      "|           water| 28| 18| 24| 13| 17|  5|  9|\n",
      "+----------------+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Are there more or less types of each each generation\n",
    "df.crosstab('type1', 'generation').sort('type1_generation').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ab321de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|   type1|       avg(attack)|\n",
      "+--------+------------------+\n",
      "|  dragon| 106.4074074074074|\n",
      "|fighting| 99.17857142857143|\n",
      "|  ground|           94.8125|\n",
      "|   steel| 93.08333333333333|\n",
      "|    rock| 90.66666666666667|\n",
      "|    dark| 87.79310344827586|\n",
      "|    fire|              81.5|\n",
      "|  normal| 75.16190476190476|\n",
      "|   grass| 73.76923076923077|\n",
      "|   water| 73.30701754385964|\n",
      "|     ice| 73.30434782608695|\n",
      "|   ghost| 72.74074074074075|\n",
      "|  poison|          72.65625|\n",
      "|electric| 70.82051282051282|\n",
      "|     bug|            70.125|\n",
      "|  flying| 66.66666666666667|\n",
      "| psychic| 65.56603773584905|\n",
      "|   fairy|62.111111111111114|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('type1').agg({'attack': 'mean'}).sort('avg(attack)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cb97282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "# 1 Select the column with both attacks mutliplied\n",
    "df = df.withColumn(\"full_attack\", col(\"attack\") + col('sp_attack'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "68240d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+-----------+\n",
      "|attack|sp_attack|full_attack|\n",
      "+------+---------+-----------+\n",
      "|    49|       65|        114|\n",
      "|    62|       80|        142|\n",
      "|   100|      122|        222|\n",
      "|    52|       60|        112|\n",
      "|    64|       80|        144|\n",
      "+------+---------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('attack', 'sp_attack', 'full_attack').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4889ce57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|   type1|  avg(full_attack)|\n",
      "+--------+------------------+\n",
      "|  dragon|             196.0|\n",
      "|    fire|169.23076923076923|\n",
      "|   steel|165.79166666666666|\n",
      "|    dark|162.31034482758622|\n",
      "|electric|158.35897435897436|\n",
      "| psychic|158.16981132075472|\n",
      "|   ghost| 155.1851851851852|\n",
      "|    rock|153.86666666666667|\n",
      "|     ice| 150.7391304347826|\n",
      "|  flying|150.66666666666666|\n",
      "|fighting|149.28571428571428|\n",
      "|   grass| 148.0897435897436|\n",
      "|   water| 147.3684210526316|\n",
      "|  ground|            146.75|\n",
      "|   fairy|143.61111111111111|\n",
      "|  poison|         134.21875|\n",
      "|  normal|132.14285714285714|\n",
      "|     bug|126.77777777777777|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look if the results are still the same\n",
    "df.groupby('type1').agg({'full_attack': 'mean'}).sort('avg(full_attack)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ea12501-fac2-425c-9ccd-abce01bba934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove full attack <= 100\n",
    "new_df = df.filter(df.full_attack > 100).na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68cf04db-0fd9-4216-8ba7-c69f883bb3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|full_attack|\n",
      "+-----------+\n",
      "|        114|\n",
      "|        142|\n",
      "|        222|\n",
      "|        263|\n",
      "|        135|\n",
      "|        165|\n",
      "|        110|\n",
      "|        215|\n",
      "|        151|\n",
      "|        167|\n",
      "|        187|\n",
      "|        155|\n",
      "|        145|\n",
      "|        125|\n",
      "|        150|\n",
      "|        190|\n",
      "|        115|\n",
      "|        155|\n",
      "|        155|\n",
      "|        165|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select('full_attack').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c6615fa-9489-4673-bce4-cee2b1530413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|full_attack|\n",
      "+-----------+\n",
      "|         25|\n",
      "|         20|\n",
      "|         25|\n",
      "|         20|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select('full_attack').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5ecfe-db08-4e02-a111-9478a43104f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Based on some statistics (attack defence, sp attack , sp defence , height, hp, speed, weight) can you predict type?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
